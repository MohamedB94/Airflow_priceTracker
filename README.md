# Syst√®me de Suivi des Prix E-commerce avec Airflow

Ce projet est un syst√®me complet de suivi des prix de produits e-commerce utilisant Apache Airflow avec Docker pour l'automatisation des t√¢ches.

## üöÄ Fonctionnalit√©s

- **Suivi automatique des prix** : Surveillance r√©guli√®re des prix de multiples produits en ligne
- **Alertes de prix** : Notifications lorsque les prix baissent ou atteignent un seuil sp√©cifi√©
- **Visualisation des tendances** : Graphiques et tableaux de bord pour analyser l'√©volution des prix
- **Automatisation avec Airflow** : Planification et gestion des t√¢ches via une interface web intuitive
- **D√©ploiement Docker** : Environnement isol√© et coh√©rent pour √©viter les probl√®mes de compatibilit√©
- **Scraping intelligent** : D√©tection automatique des s√©lecteurs pour diff√©rents sites e-commerce
- **Interface utilisateur intuitive** : Menus interactifs pour g√©rer les fonctionnalit√©s
- **Historique complet** : Donn√©es de prix stock√©es en CSV pour analyse √† long terme
- **Dashboard interactif** : Visualisation en temps r√©el des tendances de prix

## üìã Table des mati√®res

1. [Pr√©requis](#pr√©requis)
2. [Installation](#installation)
3. [D√©marrage rapide](#d√©marrage-rapide)
4. [Utilisation d'Airflow avec Docker](#utilisation-dairflow-avec-docker)
5. [Tableau de bord](#tableau-de-bord)
6. [Structure du projet](#structure-du-projet)
7. [DAGs et scripts](#dags-et-scripts)
8. [D√©pannage](#d√©pannage)
9. [Solutions cloud](#solutions-cloud)

## üîß Pr√©requis

- **Docker Desktop** pour Windows (derni√®re version)
- **Python 3.8+** pour l'interface utilisateur locale et le tableau de bord
- **Navigateur web moderne** pour acc√©der aux interfaces Airflow et au tableau de bord

## üíª Installation

### Option 1: Installation avec Docker (recommand√©e)

1. Assurez-vous que Docker Desktop est install√© et en cours d'ex√©cution
2. Clonez ou t√©l√©chargez ce d√©p√¥t dans `c:\xampp\htdocs\Airflow` ou tout autre emplacement de votre choix
3. Ouvrez une invite de commande ou PowerShell dans ce dossier

### Option 2: Installation Python locale (pour d√©veloppement uniquement)

1. Clonez ce d√©p√¥t
2. Cr√©ez un environnement virtuel:
   ```
   python -m venv airflow_env
   ```
3. Activez l'environnement:
   ```
   airflow_env\Scripts\activate
   ```
4. Installez les d√©pendances:
   ```
   pip install -r requirements.txt
   ```

## üöÄ D√©marrage rapide

### Interface utilisateur du suivi de prix

Pour lancer l'interface utilisateur de suivi de prix:

```
python price_tracking.py
```

Cette interface vous permettra de:

- Ajouter de nouveaux produits √† suivre
- V√©rifier les prix actuels
- Visualiser les tendances de prix
- G√©n√©rer des rapports
- Configurer des alertes

### Airflow avec Docker (m√©thode simplifi√©e)

1. Ouvrez une invite de commande dans le dossier du projet
2. Ex√©cutez:
   ```
   .\airflow.bat
   ```
3. Acc√©dez √† l'interface web d'Airflow: http://localhost:8080
4. Connectez-vous avec les identifiants par d√©faut: admin / admin
5. Pour arr√™ter Airflow:
   ```
   .\airflow_stop.bat
   ```

### Tableau de bord de suivi des prix

Pour lancer le tableau de bord interactif:

1. Ouvrez une invite de commande dans le dossier du projet
2. Ex√©cutez:
   ```
   .\start_dashboard.bat
   ```
3. Le tableau de bord s'ouvrira automatiquement dans votre navigateur √† l'adresse: http://localhost:8050

## üê≥ Utilisation d'Airflow avec Docker

### D√©marrer Airflow

1. Ouvrez une invite de commande ou PowerShell
2. Naviguez vers le dossier du projet: `cd c:\xampp\htdocs\Airflow`
3. Ex√©cutez le script de d√©marrage: `.\airflow.bat`
4. Attendez que les conteneurs d√©marrent (environ 30-60 secondes)
5. Acc√©dez √† l'interface web: http://localhost:8080
6. Identifiants par d√©faut: admin / admin

### V√©rifier l'√©tat des conteneurs

```
docker ps --filter "name=airflow"
```

### Consulter les logs

```
docker logs airflow-webserver
docker logs airflow-scheduler
```

### Arr√™ter Airflow

```
docker-compose down
```

ou

```
.\airflow_stop.bat
```

### R√©initialiser compl√®tement l'environnement

Si vous rencontrez des probl√®mes ou si vous souhaitez repartir de z√©ro:

```
.\airflow_rebuild.bat
```

## üìä Tableau de bord

Le tableau de bord de suivi des prix offre une interface visuelle pour analyser les tendances et les variations de prix:

### Fonctionnalit√©s du tableau de bord

- **Graphiques d'√©volution des prix** : Visualisez les tendances sur diff√©rentes p√©riodes
- **Statistiques de prix** : Min, max, moyenne et variation pour chaque produit
- **Alertes visuelles** : Notifications pour les prix bas ou en baisse significative
- **Filtres personnalis√©s** : S√©lectionnez des produits et p√©riodes sp√©cifiques
- **Rafra√Æchissement automatique** : Mise √† jour des donn√©es toutes les 5 minutes

### D√©marrage du tableau de bord

```
.\start_dashboard.bat
```

Acc√©dez au tableau de bord via: http://localhost:8050

## üìÅ Structure du projet

```
Airflow/
‚îú‚îÄ‚îÄ airflow.bat               # Script de d√©marrage principal d'Airflow avec Docker
‚îú‚îÄ‚îÄ airflow_stop.bat          # Script pour arr√™ter Airflow proprement
‚îú‚îÄ‚îÄ airflow_rebuild.bat       # Script pour reconstruire les images Docker
‚îú‚îÄ‚îÄ airflow_tasks.py          # Interface interactive pour g√©rer Airflow
‚îú‚îÄ‚îÄ docker-compose.yml        # Configuration Docker pour Airflow
‚îú‚îÄ‚îÄ Dockerfile                # Configuration de l'image Docker personnalis√©e
‚îú‚îÄ‚îÄ start_dashboard.bat       # Script pour lancer le tableau de bord
‚îú‚îÄ‚îÄ dags/                     # Dossier contenant les DAGs Airflow
‚îÇ   ‚îî‚îÄ‚îÄ price_tracker_dag.py  # DAG principal pour le suivi des prix
‚îú‚îÄ‚îÄ scripts/                  # Scripts Python utilis√©s par les DAGs
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py            # Module de scraping des prix
‚îÇ   ‚îú‚îÄ‚îÄ processor.py          # Traitement des donn√©es de prix
‚îÇ   ‚îú‚îÄ‚îÄ visualizer.py         # G√©n√©ration de graphiques et visualisations
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_improved.py # Tableau de bord Dash am√©lior√©
‚îÇ   ‚îî‚îÄ‚îÄ save_price.py         # Sauvegarde des donn√©es de prix
‚îú‚îÄ‚îÄ plugins/                  # Plugins Airflow personnalis√©s
‚îú‚îÄ‚îÄ logs/                     # Logs g√©n√©r√©s par Airflow
‚îú‚îÄ‚îÄ data/                     # Donn√©es stock√©es (CSV des prix, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ prices.csv            # Historique des prix
‚îÇ   ‚îî‚îÄ‚îÄ products.json         # Configuration des produits suivis
‚îú‚îÄ‚îÄ price_tracking.py         # Interface utilisateur pour le suivi des prix
‚îú‚îÄ‚îÄ improved_dashboard.py     # Lanceur de tableau de bord avec gestion d'erreurs
‚îú‚îÄ‚îÄ clean_prices_data.py      # Utilitaire pour nettoyer les donn√©es de prix
‚îî‚îÄ‚îÄ requirements.txt          # D√©pendances Python
```

## üìä DAGs et scripts

### DAG de suivi des prix (`price_tracker_dag.py`)

Ce DAG principal automatise le processus de suivi des prix:

1. **Scraping des sites e-commerce** : Collecte les prix actuels
2. **Traitement des donn√©es** : Nettoyage et structuration
3. **D√©tection des baisses de prix** : Identification des opportunit√©s
4. **G√©n√©ration de rapports** : Cr√©ation de visualisations
5. **Sauvegarde des donn√©es** : Archivage des historiques de prix

Le DAG s'ex√©cute automatiquement toutes les 6 heures pour maintenir les donn√©es √† jour.

### Scripts principaux

- **scraper.py** : Module qui extrait les prix des sites e-commerce avec gestion de cache et rotation des user-agents
- **processor.py** : Traite les donn√©es brutes et d√©tecte les changements de prix
- **visualizer.py** : G√©n√®re des graphiques et des visualisations des tendances de prix
- **dashboard_improved.py** : Interface Dash pour la visualisation interactive des donn√©es
- **save_price.py** : G√®re la sauvegarde et l'historisation des donn√©es de prix

## ‚ùì D√©pannage

### Erreurs Docker

- **Docker ne d√©marre pas** : V√©rifiez que Docker Desktop est en cours d'ex√©cution
- **Erreur de port** : Assurez-vous que les ports 8080 (Airflow) et 8050 (Dashboard) ne sont pas utilis√©s
- **Conteneurs qui s'arr√™tent** : V√©rifiez les logs avec `docker logs airflow-webserver`

### Probl√®mes d'Airflow

- **DAGs non visibles** : V√©rifiez la syntaxe du fichier DAG et red√©marrez les conteneurs
- **T√¢ches en √©chec** : Consultez les logs de la t√¢che dans l'interface web d'Airflow
- **Erreurs d'importation Python** : V√©rifiez que tous les modules n√©cessaires sont disponibles

### Probl√®mes de scraping

- **√âchec du scraping** : Le site peut avoir chang√© sa structure ou bloqu√© les requ√™tes
- **Donn√©es manquantes** : V√©rifiez les s√©lecteurs CSS dans la configuration des produits
- **Trop de requ√™tes** : Ajustez les d√©lais entre les requ√™tes pour √©viter d'√™tre bloqu√©

### Probl√®mes de tableau de bord

- **Erreurs Dash** : V√©rifiez que les d√©pendances (dash, plotly, pandas) sont install√©es
- **Donn√©es non affich√©es** : Assurez-vous que le fichier prices.csv existe et contient des donn√©es
- **Crash du tableau de bord** : Consultez les logs dans la console pour identifier l'erreur

## ‚òÅÔ∏è Migration vers AWS Cloud

Dans le cadre d'une √©volution vers une architecture cloud robuste et scalable, j'ai con√ßu une solution AWS compl√®te pour notre syst√®me de suivi des prix e-commerce.

### Architecture AWS propos√©e

![Architecture AWS pour le syst√®me de suivi des prix](https://excalidraw.com/#json=LkbFLMaZoX7h0AFSF1LUB,cwIJJF2oK3J3IzULuEaZiQ)

### Composants cl√©s de l'architecture AWS

1. **Amazon MWAA (Managed Workflows for Apache Airflow)**

   - Service Airflow enti√®rement g√©r√©, √©liminant la gestion manuelle de l'infrastructure
   - DAGs stock√©s dans un bucket S3 d√©di√© avec versioning
   - Auto-scaling int√©gr√© pour g√©rer les pics de charge lors des op√©rations de scraping

2. **AWS Lambda pour le scraping et le traitement**

   - Fonctions serverless rempla√ßant les scripts Python actuels
   - Fonction de scraping d√©clench√©e par les DAGs MWAA
   - Fonction de traitement pour nettoyer et transformer les donn√©es collect√©es
   - Fonction de notification pour les alertes de prix via SNS/SES

3. **Amazon S3 pour le stockage des donn√©es**

   - Bucket principal pour les donn√©es de prix structur√©es en CSV/Parquet
   - Bucket pour les sauvegardes avec politique de r√©tention configurable
   - Bucket pour les DAGs d'Airflow et les artefacts de d√©ploiement

### Flux de donn√©es et processus

1. **Collecte des donn√©es**

   - Les DAGs MWAA d√©clenchent les fonctions Lambda de scraping √† intervalles r√©guliers
   - Les donn√©es brutes sont stock√©es dans S3 dans une zone "raw"

2. **Traitement et transformation**

   - Les fonctions Lambda de traitement sont d√©clench√©es apr√®s la collecte
   - Les donn√©es nettoy√©es sont √©crites dans S3 (zone "processed") et dans RDS

3. **Visualisation et alertes**

   - Le service ECS h√©berge le dashboard qui lit les donn√©es depuis RDS
   - Les alertes de prix sont envoy√©es via SNS aux utilisateurs abonn√©s

4. **Sauvegarde et archivage**
   - Politique de cycle de vie S3 pour archiver les donn√©es historiques
   - Backups automatiques de RDS avec r√©tention configurable

### Avantages de cette architecture AWS

- **Haute disponibilit√©** : Tous les services sont con√ßus avec redondance
- **Scalabilit√©** : Capacit√© √† suivre des milliers de produits sans reconfiguration
- **Co√ªt optimis√©** : Paiement √† l'usage, pas d'infrastructure idle
- **S√©curit√© renforc√©e** : Chiffrement et contr√¥le d'acc√®s pr√©cis
- **Op√©rations simplifi√©es** : Services manag√©s r√©duisant la charge op√©rationnelle
- **Performance** : Ressources adapt√©es dynamiquement aux besoins

### Pipeline CI/CD

Le pipeline CI/CD automatise enti√®rement le processus de d√©ploiement:

1. **Source**: D√©tection des changements dans le d√©p√¥t GitHub
2. **Build**:
   - Construction des images Docker pour le scraper et le dashboard
   - Packaging des fonctions Lambda
   - Ex√©cution des tests unitaires
3. **Test**:
   - Tests d'int√©gration dans un environnement de staging
   - Validation des DAGs Airflow
   - Tests de performance
4. **Deploy**:
   - D√©ploiement des DAGs dans le bucket S3 MWAA
   - Mise √† jour des fonctions Lambda
   - D√©ploiement des nouvelles images Docker vers ECS
   - Ex√©cution des migrations de base de donn√©es si n√©cessaire

### Co√ªts estim√©s

Pour un syst√®me de suivi surveillant environ 500 produits:

- MWAA: ~$250/mois (environnement de petite taille)
- Lambda: ~$20/mois (ex√©cutions quotidiennes)
- S3: ~$5/mois (stockage et requ√™tes)
- RDS: ~$50/mois (instance db.t3.small)
- ECS/Fargate: ~$40/mois (dashboard)
- Autres services: ~$20/mois

**Total estim√©**: ~$385/mois, avec possibilit√© d'optimisation selon l'usage r√©el.

Cette architecture AWS repr√©sente une √©volution naturelle de notre solution Docker actuelle, permettant de conserver les m√™mes fonctionnalit√©s tout en ajoutant scalabilit√©, fiabilit√© et performances am√©lior√©es.

---

## Architecture Cloud AWS

### Pr√©sentation

Voici une architecture cloud bas√©e sur AWS pour le projet de suivi des prix e-commerce. Cette solution utilise des services manag√©s pour garantir scalabilit√©, fiabilit√© et simplicit√© de gestion.

### Sch√©ma d'architecture

![Sch√©ma AWS](schemaAWS.png)

### Composants principaux

1. **AWS CodePipeline** : Automatisation du d√©ploiement des DAGs, des fonctions Lambda, et du tableau de bord.
2. **AWS MWAA** : Orchestration des workflows Airflow pour g√©rer les t√¢ches de scraping, traitement, et sauvegarde.
3. **AWS Lambda** : Ex√©cution des scripts de scraping, transformation des donn√©es, et g√©n√©ration des alertes.
4. **Amazon S3** : Stockage des fichiers CSV contenant les donn√©es de prix collect√©es.
5. **Amazon RDS** : Base de donn√©es relationnelle pour stocker les donn√©es historiques des prix.
6. **AWS ECS/Fargate** : H√©bergement du tableau de bord interactif (Dash/Plotly).
7. **AWS CloudWatch** : Surveillance des performances des workflows, des fonctions Lambda, et des conteneurs ECS.

### Flux de donn√©es

1. **D√©ploiement** :
   - AWS CodePipeline d√©ploie les DAGs dans MWAA, les fonctions Lambda, et le tableau de bord dans ECS/Fargate.
2. **Collecte des donn√©es** :
   - MWAA d√©clenche les fonctions Lambda pour ex√©cuter les t√¢ches de scraping.
   - Les donn√©es collect√©es sont sauvegard√©es dans Amazon S3.
3. **Traitement et stockage** :
   - Les fonctions Lambda traitent les donn√©es et les sauvegardent dans Amazon RDS.
4. **Visualisation** :
   - ECS/Fargate h√©berge le tableau de bord interactif qui r√©cup√®re les donn√©es depuis Amazon RDS.
5. **Surveillance** :
   - AWS CloudWatch surveille les performances et configure des alertes en cas d'erreurs.

## üìú Licence

Projet interne - Utilisation r√©serv√©e.

---

Derni√®re mise √† jour : 16 juin 2025

_Ce README regroupe toute la documentation sur Airflow avec Docker, le syst√®me de suivi des prix e-commerce et le tableau de bord interactif._
